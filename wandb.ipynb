{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight & Biases (WandB) module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get configuration details of any run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity, project, run_id = \"ammar20112001-ml\", \"Attention-Is-All-You-Need--reproduced\", \"uyow0rcm\"\n",
    "run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "\n",
    "print('CONFIG')\n",
    "for key, value in run.config.items():\n",
    "  print(key, ':', value)\n",
    "print('\\nSUMMARY')\n",
    "for key, value in run.summary.items():\n",
    "  print(key, ':', value)\n",
    "print('\\nGit commit:', run.commit, '\\n')\n",
    "run.history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read metrics from a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "if run.state == \"finished\":\n",
    "    for i, row in run.history().iterrows():\n",
    "        print(row[\"_timestamp\"], row[\"LOSS_step\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare two runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with your <entity>, <project>, and <run_id>\n",
    "run1 = api.run(f\"{entity}/{project}/uyow0rcm\")\n",
    "run2 = api.run(f\"{entity}/{project}/1mj38s4b\")\n",
    "\n",
    "\n",
    "df = pd.DataFrame([run1.config, run2.config]).transpose()\n",
    "\n",
    "df.columns = [run1.name, run2.name]\n",
    "print(df[df[run1.name] != df[run2.name]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export experiment manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "n_epochs = 5\n",
    "config = {\"n_epochs\": n_epochs}\n",
    "run = wandb.init(project=project, config=config)\n",
    "for n in range(run.config.get(\"n_epochs\")):\n",
    "    run.log(\n",
    "        {\"val\": random.randint(0, 1000), \"loss\": (random.randint(0, 1000) / 1000.00)}\n",
    "    )\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying Multiple Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "entity, project = \"ammar20112001-ml\", \"Attention-Is-All-You-Need--reproduced\"\n",
    "\n",
    "runs = api.runs(entity + \"/\" + project)\n",
    "\n",
    "summary_list, config_list, name_list = [], [], []\n",
    "for run in runs:\n",
    "    # .summary contains output keys/values for\n",
    "    # metrics such as accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary_list.append(run.summary._json_dict)\n",
    "\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    config_list.append({k: v for k, v in run.config.items() if not k.startswith(\"_\")})\n",
    "\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "runs_df = pd.DataFrame(\n",
    "    {\"summary\": summary_list, \"config\": config_list, \"name\": name_list}\n",
    ")\n",
    "\n",
    "runs_df.to_csv(\"project.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update metrics for a run, after the run has finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = api.run(f\"{entity}/{project}/1mj38s4b\")\n",
    "run.summary[\"loss\"] = 100\n",
    "#run.summary[\"accuracy_histogram\"] = wandb.Histogram(numpy_array)\n",
    "run.summary.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity, project, run_id = \"ammar20112001-ml\", \"Attention-Is-All-You-Need--reproduced\", \"a403ono3\"\n",
    "run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "\n",
    "hist = run.history()  # and pull down a sample of the data as a pandas DataFrame\n",
    "\n",
    "# which artifacts where created and logged?\n",
    "artifacts = run.logged_artifacts()\n",
    "\n",
    "for artifact in artifacts:\n",
    "    print(f\"artifact of type {artifact.type}: {artifact.name}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
