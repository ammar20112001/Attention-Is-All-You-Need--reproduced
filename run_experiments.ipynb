{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "if \"bootstrap\" not in locals():\n",
        "    # path management for Python\n",
        "    pythonpath, = !echo $PYTHONPATH\n",
        "    if \".\" not in pythonpath.split(\":\"):\n",
        "        pythonpath = \".:\" + pythonpath\n",
        "        %env PYTHONPATH={pythonpath}\n",
        "        !echo $PYTHONPATH\n",
        "\n",
        "    # get both Colab and local notebooks into the same state\n",
        "    !wget --quiet https://gist.githubusercontent.com/ammar20112001/2874c7b494dcdbd905c533362f496cc5/raw/37722b66d6b801d7e199553047664f1c1375f20d/bootstrap_transformers.py -O bootstrap.py\n",
        "    import bootstrap\n",
        "\n",
        "    !pip -q install -r requirement.txt\n",
        "    !ls"
      ],
      "metadata": {
        "id": "YA2Yy6776Ylb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fbc2cd5-6aba-492d-900a-1494d67db731"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=.:/env/python\n",
            ".:/env/python\n",
            "config.py   lit_data_module.py\tmodel.py   requirements_all.txt  run_experiments.ipynb\n",
            "dataset.py  lit_model.py\tREADME.md  requirement.txt\t train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python3 train.py fit --trainer.max_epochs=2 --optimizer=Adam --optimizer.lr=0.001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA2fy45K_wIP",
        "outputId": "df8afabf-0481-4bf3-bdc8-e6940c26a512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " kaitchup/opus-English-to-French \n",
            "\n",
            "\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 243kB/s]\n",
            "config.json: 100% 570/570 [00:00<00:00, 3.51MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 941kB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 942kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/lightning/fabric/utilities/seed.py:42: No seed found, seed set to 0\n",
            "Seed set to 0\n",
            "README.md: 100% 397/397 [00:00<00:00, 2.72MB/s]\n",
            "validation-00000-of-00001.parquet: 100% 332k/332k [00:00<00:00, 31.6MB/s]\n",
            "train-00000-of-00001.parquet: 100% 94.3M/94.3M [00:00<00:00, 365MB/s]\n",
            "Generating validation split: 100% 2000/2000 [00:00<00:00, 308030.99 examples/s]\n",
            "Generating train split: 100% 897747/897747 [00:01<00:00, 784342.54 examples/s]\n",
            "Map: 100% 2000/2000 [00:00<00:00, 3853.71 examples/s]\n",
            "Map: 100% 897747/897747 [02:04<00:00, 7199.83 examples/s]\n",
            "\n",
            "\n",
            "TRAIN/VAL/TEST SETS:\n",
            "807971\n",
            "44888\n",
            "44889\n",
            "\n",
            "\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "2024-09-23 16:32:18.832472: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-23 16:32:18.865668: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-23 16:32:18.876484: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-23 16:32:18.898566: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-09-23 16:32:20.626214: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name        | Type        | Params | Mode \n",
            "----------------------------------------------------\n",
            "0 | transformer | Transformer | 36.3 M | train\n",
            "----------------------------------------------------\n",
            "36.3 M    Trainable params\n",
            "0         Non-trainable params\n",
            "36.3 M    Total params\n",
            "145.126   Total estimated model params size (MB)\n",
            "150       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Epoch 0: 100% 12625/12625 [3:36:36<00:00,  1.03s/it, v_num=0, LOSS_step=3.580]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/702 [00:00<?, ?it/s]      \u001b[A\n",
            "Validation DataLoader 0:   0% 0/702 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   3% 20/702 [00:06<03:41,  3.08it/s]\u001b[A\n",
            "Validation DataLoader 0:   6% 40/702 [00:13<03:40,  3.01it/s]\u001b[A\n",
            "Validation DataLoader 0:   9% 60/702 [00:20<03:34,  2.99it/s]\u001b[A\n",
            "Validation DataLoader 0:  11% 80/702 [00:26<03:28,  2.98it/s]\u001b[A\n",
            "Validation DataLoader 0:  14% 100/702 [00:33<03:22,  2.97it/s]\u001b[A\n",
            "Validation DataLoader 0:  17% 120/702 [00:40<03:16,  2.97it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 140/702 [00:47<03:09,  2.97it/s]\u001b[A\n",
            "Validation DataLoader 0:  23% 160/702 [00:53<03:02,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  26% 180/702 [01:00<02:56,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  28% 200/702 [01:07<02:49,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  31% 220/702 [01:14<02:42,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  34% 240/702 [01:21<02:36,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  37% 260/702 [01:27<02:29,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 280/702 [01:34<02:22,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  43% 300/702 [01:41<02:15,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  46% 320/702 [01:48<02:09,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  48% 340/702 [01:54<02:02,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  51% 360/702 [02:01<01:55,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  54% 380/702 [02:08<01:48,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  57% 400/702 [02:15<01:42,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 420/702 [02:21<01:35,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  63% 440/702 [02:28<01:28,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  66% 460/702 [02:35<01:21,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  68% 480/702 [02:42<01:15,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  71% 500/702 [02:48<01:08,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  74% 520/702 [02:55<01:01,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  77% 540/702 [03:02<00:54,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 560/702 [03:09<00:47,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  83% 580/702 [03:15<00:41,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  85% 600/702 [03:22<00:34,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  88% 620/702 [03:29<00:27,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  91% 640/702 [03:36<00:20,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  94% 660/702 [03:43<00:14,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0:  97% 680/702 [03:49<00:07,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 700/702 [03:56<00:00,  2.96it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 702/702 [03:57<00:00,  2.96it/s]\u001b[A\n",
            "Epoch 1:   3% 340/12625 [05:50<3:30:49,  1.03s/it, v_num=0, LOSS_step=3.230, LOSS_VAL=3.230, LOSS_epoch=3.900]"
          ]
        }
      ]
    }
  ]
}