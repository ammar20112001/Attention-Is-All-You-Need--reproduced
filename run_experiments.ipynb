{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "if \"bootstrap\" not in locals():\n",
        "    # path management for Python\n",
        "    pythonpath, = !echo $PYTHONPATH\n",
        "    if \".\" not in pythonpath.split(\":\"):\n",
        "        pythonpath = \".:\" + pythonpath\n",
        "        %env PYTHONPATH={pythonpath}\n",
        "        !echo $PYTHONPATH\n",
        "\n",
        "    # get both Colab and local notebooks into the same state\n",
        "    !wget --quiet https://gist.githubusercontent.com/ammar20112001/2874c7b494dcdbd905c533362f496cc5/raw/37722b66d6b801d7e199553047664f1c1375f20d/bootstrap_transformers.py -O bootstrap.py\n",
        "    import bootstrap\n",
        "\n",
        "    #!pip install -r requirement.txt"
      ],
      "metadata": {
        "id": "YA2Yy6776Ylb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zSNwW9E-YdA",
        "outputId": "67e7ba4d-b9e9-4a5e-8545-9ce5902f1aa3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.py   lit_data_module.py\tmodel.py   requirements_all.txt  train.py\n",
            "dataset.py  lit_model.py\tREADME.md  requirement.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python3 train.py fit --trainer.max_epochs=2 --optimizer=Adam --optimizer.lr=0.001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA2fy45K_wIP",
        "outputId": "30825ba4-8a0d-477a-fad5-58347094dd87"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " kaitchup/opus-English-to-French \n",
            "\n",
            "\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 327kB/s]\n",
            "config.json: 100% 570/570 [00:00<00:00, 3.36MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 1.35MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 1.92MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/lightning/fabric/utilities/seed.py:42: No seed found, seed set to 0\n",
            "Seed set to 0\n",
            "README.md: 100% 397/397 [00:00<00:00, 2.52MB/s]\n",
            "validation-00000-of-00001.parquet: 100% 332k/332k [00:00<00:00, 10.5MB/s]\n",
            "train-00000-of-00001.parquet: 100% 94.3M/94.3M [00:01<00:00, 77.7MB/s]\n",
            "Generating validation split: 100% 2000/2000 [00:00<00:00, 341917.67 examples/s]\n",
            "Generating train split: 100% 897747/897747 [00:00<00:00, 971484.61 examples/s]\n",
            "Map:  50% 1000/2000 [00:00<00:00, 5526.00 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "Map: 100% 2000/2000 [00:00<00:00, 5540.54 examples/s]\n",
            "Map: 100% 897747/897747 [02:06<00:00, 7090.48 examples/s]\n",
            "\n",
            "\n",
            "TRAIN/VAL/TEST SETS:\n",
            "807971\n",
            "44888\n",
            "44889\n",
            "\n",
            "\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "2024-09-22 19:43:17.461731: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-22 19:43:17.483499: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-22 19:43:17.489304: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-22 19:43:17.503334: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-09-22 19:43:18.828118: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name        | Type        | Params | Mode \n",
            "----------------------------------------------------\n",
            "0 | transformer | Transformer | 36.3 M | train\n",
            "----------------------------------------------------\n",
            "36.3 M    Trainable params\n",
            "0         Non-trainable params\n",
            "36.3 M    Total params\n",
            "145.126   Total estimated model params size (MB)\n",
            "150       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Epoch 0:   0% 0/25250 [00:00<?, ?it/s] \n",
            "\n",
            "encoder_input: torch.Size([32, 256])\n",
            "decoder_input: torch.Size([32, 256])\n",
            "labels: torch.Size([32, 256])\n",
            "encoder_mask: torch.Size([32, 1, 1, 256])\n",
            "decoder_mask: torch.Size([32, 1, 256, 256])\n",
            "\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/image-to-text-resnet-transformer/train.py\", line 9, in <module>\n",
            "    cli = LightningCLI(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/cli.py\", line 394, in __init__\n",
            "    self._run_subcommand(self.subcommand)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/cli.py\", line 701, in _run_subcommand\n",
            "    fn(**fn_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 538, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 574, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 981, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 1025, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
            "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
            "    self._optimizer_step(batch_idx, closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
            "    call._call_lightning_module_hook(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/core/module.py\", line 1306, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/core/optimizer.py\", line 153, in step\n",
            "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/strategy.py\", line 238, in optimizer_step\n",
            "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/plugins/precision/precision.py\", line 122, in optimizer_step\n",
            "    return optimizer.step(closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 89, in _use_grad\n",
            "    ret = func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\", line 205, in step\n",
            "    loss = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
            "    closure_result = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
            "    self._result = self.closure(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/optimization/automatic.py\", line 129, in closure\n",
            "    step_output = self._step_fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/optimization/automatic.py\", line 317, in _training_step\n",
            "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 319, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/strategy.py\", line 390, in training_step\n",
            "    return self.lightning_module.training_step(*args, **kwargs)\n",
            "  File \"/content/image-to-text-resnet-transformer/lit_model.py\", line 51, in training_step\n",
            "    loss = torch.nn.functional.nll_loss(logits, labels.view(-1))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 2778, in nll_loss\n",
            "    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)\n",
            "ValueError: Expected input batch_size (32) to match target batch_size (8192).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4wT4NGH5cl7"
      },
      "outputs": [],
      "source": [
        "'''if \"bootstrap\" not in locals() or bootstrap.run:\n",
        "    # path management for Python\n",
        "    pythonpath, = !echo $PYTHONPATH\n",
        "    if \".\" not in pythonpath.split(\":\"):\n",
        "        pythonpath = \".:\" + pythonpath\n",
        "        %env PYTHONPATH={pythonpath}\n",
        "        !echo $PYTHONPATH\n",
        "\n",
        "    # get both Colab and local notebooks into the same state\n",
        "    !wget --quiet https://gist.githubusercontent.com/ammar20112001/09ae615178276e403181495b63cd27f1/raw/9a5d98e76298fc32a171e2020ba39a1d47207db9/bootstrap.py -O bootstrap.py\n",
        "    import bootstrap\n",
        "\n",
        "    # change into the lab directory\n",
        "    bootstrap.change_to_lab_dir(lab_idx=lab_idx)\n",
        "\n",
        "    # allow \"hot-reloading\" of modules\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2\n",
        "    # needed for inline plots in some contexts\n",
        "    %matplotlib inline\n",
        "\n",
        "    bootstrap.run = False  # change to True re-run setup\n",
        "\n",
        "!pwd\n",
        "%ls'''"
      ]
    }
  ]
}