{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "if \"bootstrap\" not in locals():\n",
        "    # path management for Python\n",
        "    pythonpath, = !echo $PYTHONPATH\n",
        "    if \".\" not in pythonpath.split(\":\"):\n",
        "        pythonpath = \".:\" + pythonpath\n",
        "        %env PYTHONPATH={pythonpath}\n",
        "        !echo $PYTHONPATH\n",
        "\n",
        "    # get both Colab and local notebooks into the same state\n",
        "    !wget --quiet https://gist.githubusercontent.com/ammar20112001/2874c7b494dcdbd905c533362f496cc5/raw/37722b66d6b801d7e199553047664f1c1375f20d/bootstrap_transformers.py -O bootstrap.py\n",
        "    import bootstrap\n",
        "\n",
        "    !pip -q install -r requirement.txt\n",
        "    !ls"
      ],
      "metadata": {
        "id": "YA2Yy6776Ylb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc9ffd1-edbc-491a-9504-7aa7e6211e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=.:/env/python\n",
            ".:/env/python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python3 train.py fit --trainer.max_epochs=2 --optimizer=Adam --optimizer.lr=0.001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA2fy45K_wIP",
        "outputId": "ac69d4a2-f2a9-40ad-f3af-21bce7168c23"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " kaitchup/opus-English-to-French \n",
            "\n",
            "\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 320kB/s]\n",
            "config.json: 100% 570/570 [00:00<00:00, 3.65MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 573kB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 777kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/lightning/fabric/utilities/seed.py:42: No seed found, seed set to 0\n",
            "Seed set to 0\n",
            "README.md: 100% 397/397 [00:00<00:00, 3.01MB/s]\n",
            "validation-00000-of-00001.parquet: 100% 332k/332k [00:00<00:00, 1.62MB/s]\n",
            "train-00000-of-00001.parquet: 100% 94.3M/94.3M [00:03<00:00, 26.8MB/s]\n",
            "Generating validation split: 100% 2000/2000 [00:00<00:00, 226199.49 examples/s]\n",
            "Generating train split: 100% 897747/897747 [00:01<00:00, 670741.58 examples/s]\n",
            "Map: 100% 2000/2000 [00:00<00:00, 3661.42 examples/s]\n",
            "Map: 100% 897747/897747 [02:03<00:00, 7266.97 examples/s]\n",
            "\n",
            "\n",
            "TRAIN/VAL/TEST SETS:\n",
            "807971\n",
            "44888\n",
            "44889\n",
            "\n",
            "\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "2024-09-23 14:58:36.232414: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-23 14:58:36.252280: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-23 14:58:36.258273: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-23 14:58:36.273107: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-09-23 14:58:37.523117: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name        | Type        | Params | Mode \n",
            "----------------------------------------------------\n",
            "0 | transformer | Transformer | 36.3 M | train\n",
            "----------------------------------------------------\n",
            "36.3 M    Trainable params\n",
            "0         Non-trainable params\n",
            "36.3 M    Total params\n",
            "145.126   Total estimated model params size (MB)\n",
            "150       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Epoch 0:  32% 8100/25250 [1:12:27<2:33:24,  1.86it/s, v_num=0, LOSS_step=4.040]\n",
            "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
          ]
        }
      ]
    }
  ]
}